# GO调度原理一：操作系统调度

### 前言
这是一个关于Go调度原理的系列文章，共有三个部分，本文是其中的第一篇。本系列文章将讲述Go程序调度背后的机制和语义。本文的重点则是操作系统调度。
### 介绍
Go调度器的设计和实现使得多线程Go程序更加高效、性能更好。这需要归功于Go调度器在设计时对操作系统(OS)调度器的机械同情(即软硬件协同工作)。但是，如果你的Go程序不对Go调度器机械同情(即写的代码不符合Go调度器的设计理念)，Go调度器所做的努力都会白费，你的程序也不会有很好的性能。所以了解操作系统调度和Go调度是如何让你的多线程程序并发运行的非常重要。

> mechanical sympathies - Hardware and software working together in harmony  机械同情的

这篇文章由多个部分组成，将重点讨论调度程序的更高级机制和语义。我将提供足够的信息，让你在脑海中对调度器如何工作有个画面感，以便在编码时做出更好的工程决策。尽管在多线程编程里你的工作可能更多涉及的是工程决策，但调度器的工作机制和底层语义也是非常重要的基础知识，值得你去了解。

### 操作系统调度

操作系统调度程序是软件中的复杂组成。它们必须考虑运行它们的硬件的布局和设置。这包括但不限于存在多少个处理器和内核，CPU缓存和[NUMA](https://rakyll.org/numa/)。没有这些知识，调度器将无法尽可能高效工作。幸运的是，你无需深入探讨这些主题，也可以就操作系统调度程序的工作方式建立良好的思维模型。

你的程序就是一系列待顺序执行的机器指令。为了完成这个工作，操作系统使用了线程的概念。线程的工作就是清点分配给它的工作并顺序执行。这个执行工作会持续进行直至没有指令待执行。

每个运行的程序都会创建一个进程，每个进程会分配一个初始的线程。线程可以创建更多的线程。所有这些线程都各自独立运行，在线程级别而非进程级别被调度。线程可以并发（每个线程轮流使用某个核心）或并行（线程在不同的核心同时运行）地运行。线程还会维护自己的状态，以便安全，独立地执行其指令。

操作系统调度器负责确保在有线程可被执行的情况下不会有处理器核心处于空闲状态。它也需要创造一种假象——即所有的线程可以被同时执行。为了创建这种假象，操作系统需要优先运行高优先级的线程。然而，低优先级别的线程也不能一直得不到被执行的机会处于“饥饿”状态。操作系统调度还得使用更快更好的决策来降低调度延迟。

这里面涉及到很多的调度算法，但是幸运的是，业界对此已经有了几十年的研究以及经验可以借鉴。为了更好的理解这些，我们最好来描述和定义一些重要的概念。

### 指令执行
程序计数器(PC，  program counter )，有时候也称之为指令指针（IP， [instruction pointer](https://en.wikipedia.org/wiki/Program_counter)）是用来让当前指令保持对下一条待执行指令追踪的。在大多数处理器中，PC都指向下一条指令而非当前指令。

如果你曾经看到过Go程序的堆栈，你可能会注意到在每一行最后都有一个十六进制数值。比如
**List1**中的 `+0x39` 和 `+0x72`。

**List1**

	goroutine 1 [running]:
	   main.example(0xc000042748, 0x2, 0x4, 0x106abae, 0x5, 0xa)
	       stack_trace/example1/example1.go:13 +0x39                 <- LOOK HERE
	   main.main()
	       stack_trace/example1/example1.go:8 +0x72                  <- LOOK HERE
	       
	       
这些数值表示从相对于函数起始位置的PC偏移值。`+0x39` 这个PC偏移值表示如果程序没有panic的话，下一条需要被执行的指令就是example 函数内的这个地方。`0+x72` PC偏移值则表示如果控制流回到main函数，则需要被执行的指令是`0+x72` 对应的。更重要的是，PC前面的内容可以告诉你当前正在执行的是啥指令。

下面`List2`是形成上面这个堆栈的原始代码

**List2**

	https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example1/example1.go
	07 func main() {
	08     example(make([]string, 2, 4), "hello", 10)
	09 }
	12 func example(slice []string, str string, i int) {
	13    panic("Want stack trace")
	14 }

十六进制数值`+0x39`表示 `example` 函数内一个指令的PC偏移是57字节(相对于函数起始指令)。在下面的**List3**中，你可以从二进制中看到`example` 函数的`objdump`的内容。找到在最底下的第12条指令，注意它上面的那条指令调用了`panic`。

	$ go tool objdump -S -s "main.example" ./example1
	TEXT main.example(SB) stack_trace/example1/example1.go
	func example(slice []string, str string, i int) {
	  0x104dfa0        65488b0c2530000000    MOVQ GS:0x30, CX
	  0x104dfa9        483b6110        CMPQ 0x10(CX), SP
	  0x104dfad        762c            JBE 0x104dfdb
	  0x104dfaf        4883ec18        SUBQ $0x18, SP
	  0x104dfb3        48896c2410        MOVQ BP, 0x10(SP)
	  0x104dfb8        488d6c2410        LEAQ 0x10(SP), BP
	    panic("Want stack trace")
	  0x104dfbd        488d059ca20000    LEAQ runtime.types+41504(SB), AX
	  0x104dfc4        48890424        MOVQ AX, 0(SP)
	  0x104dfc8        488d05a1870200    LEAQ main.statictmp_0(SB), AX
	  0x104dfcf        4889442408        MOVQ AX, 0x8(SP)
	  0x104dfd4        e8c735fdff        CALL runtime.gopanic(SB)
	  0x104dfd9        0f0b            UD2              <--- LOOK HERE PC(+0x39)
	  
> 记住：PC指的是下一条指令，而非当前指令。
> 


### 线程状态
另一个重要的概念是线程状态。它规定了调度器在线程中所扮演的角色。线程可以处于三种状态：**Waiting**、**Runnable**、**Executing**。

- **Waiting**。 意味着线程已经停止执行并且在等待某个东西才能继续执行。原因可能是在等硬件（磁盘、网络等）、操作系统（系统调用）、同步调用（atomic, mutexes）。这些场景下的延迟是导致性能差的根本因素。
- **Runnable**。 意味着线程在等待处理器核心分配时间给它，从而执行赋给它的指令。如果你有很多个线程都需要分配时间，那可能每个线程等的时间就会更久。同样，每个线程分配到的时间也会变短，因为大家都在竞争。这种类型的调度延迟同样会带来性能下降。
- **Executing**。这意味着，线程已经被放到某个处理器核心上并且正在执行分配给该线程的机器指令。这是每个线程都想要的状态。



### 负载类型
线程做的工作可以分为2种类型。

- **CPU-Bound（CPU约束型）**：这种类型的工作永远不会导致线程处于**Waiting**状态。这种工作需要持续性地进行计算。计算Pi小数点后N位可以视为CPU约束型。
- **IO-Bound（IO约束型）**：这种类型工作会导致线程进入到**Waiting**状态。这种工作包括请求网络资源或者是通过操作系统发起系统调用。一个需要访问数据库的线程可能是个IO约束型。这里我将把会导致线程等待的同步事件（mutexes, atomic）也纳入到这个范畴。


### 上下文切换
如果你程序是在Linux, Mac 或者 Windows操作系统上运行，那么你程序将运行在一个有抢占式调度器的操作系统上。这意味着几个重要的点。

- 首先，这意味着，对调度器而言，在某个给定时间点，哪个线程会被选中执行是不可预测的。线程优先级与事件（例如在网络上接收数据）一起使得无法确定调度程序将选择做什么以及何时做。
- 其次，这意味着你绝不能基于自己有幸经历但无法保证每次都能发生的某些感知行为编写代码。不能因为我已经看到这种情况以1000次相同的方式发生，就认为这是有保证的行为。如果你需要在应用程序中的确定性，则必须控制线程的同步和编排。

在内核上交换线程的物理行为称为**上下文切换**。当调度程序从内核中拉出一个正在执行的线程(**Executing**)并将其替换为可运行线程（**Runnable**）时，就会发生上下文切换。从运行队列中选择的线程将进入**Executing**状态。被拉出的线程可以移回“**Runnable**”状态（如果它仍具有运行能力）或“**Waiting**”状态（如果由于IO-Bound类型的请求而被替换）。

上下文切换被认为是很浪费性能的，因为将线程从内核切走和切入都是需要花费时间的。上下文切换带来的延迟由很多因素决定，但是一个合理的值是 [~1000 至 ~1500](https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/) 纳秒。考虑到平均每个核[每纳秒可执行12条指令](https://www.youtube.com/watch?v=jEG4Qyo_4Bc&feature=youtu.be&t=266)，每次上下文切换将导致~12k 至 ~18k 条指令的延迟。本质上，这将导致你的程序在上下文切换时将失去执行大量指令的能力。

如果你的程序主要处理的是**IO约束型**的工作，上下文切换反而会带来优势。一旦某个线程进入**Waiting**状态，另外一个**Runnable**状态的线程将会替代它的位置去执行。这是调度器的最重要内容之一。如果有工作要做（线程处于可运行状态），则不允许内核处于闲置状态。

如果你的程序主要处理的是**CPU约束型**的工作，那上下文切换将会是梦魇。由于线程一直有事情要做，上线文切换会暂停这个事情。这种情况与**IO约束型**的工作形成鲜明对比。

### 少即是多
在早期处理器只有一个核心的时候，调度工作并不复杂。因为只有一个处理器以及一个核，在任意给定时刻只会有一个线程在执行。当时的思路是定义一个[调度周期](https://lwn.net/Articles/404993/)，并且执行在这个时间点所有处于**Runnable**状态的线程。没关系，用调度周期除以这个时间内**Runnable**状态的线程个数就可以了。

举个例子，假如你定义调度周期为1000ms（即1s），这样的话平均每个线程分配有100ms的执行时间。假如你有100个线程，那平均每个线程的分配时间就会减少到10ms。但是，当你有1000个线程的时候会怎样呢？按照上面的套路给每个线程分配1ms的执行时间是不明智的，因为你可能在上下文切换花费的时间会占据整个工作的很大比例。

你需要做的是设定一个最小时间片的限制。在上述最后一种常见里，如果最小时间片限制是10ms，并且你有1000个线程，那这样的话整个调度周期需要10000ms（即10s）。如果有10000个线程并且每个线程都用完它的时间片时间的话，整个调度周期会变成100000ms（即100s）。

注意到，这只是一种非常简化的场景，实际上调度器在做调度决策的时候还会遇到很多其它复杂场景。你在程序中控制你的线程，当有很多个线程并且有IO约束型事件发生时，会有更多的混乱和非确定性行为发生。

这就是为什么整个游戏的规则是“少即是多”。更少的处于**Runnable**状态的线程意味着更少的调度工作，也意味着每个线程可以获得更多的执行时间。更多的处于**Runnable**状态的线程意味着更多的调度工作。这意味着随着时间的流逝，完成的工作也更少了。

### 找到平衡
你需要在你所拥有的核心数以及线程数之间找到一个平衡从而获得最佳的性能。当谈论到这样的平衡的时候，线程池是一个不错的答案。我将会在第二部分给你展示在Go中使用线程池是没有必要的了。我认为这是Go做的非常好的地方，因为这样使得多线程编程变的更简单了。

在Go之前的语言如C++中，线程池对于多线程编程是至关重要的，工程师需要计算出到底多少个线程的线程池是最佳的。但是在面对不同类型的工作以及不同硬件时，可能需要不同线程数量的线程池，这会导致使用线程池这种方式来达到应用程序最佳性能变的复杂。

### 缓存线（Cache Lines）
从主存储中访问数据有非常高的延迟（~100 至 ~300个时钟周期），所以处理器核心使用本地缓存来让数据更接近需要使用他们的硬件线程。从缓存中获取数据会有较少的时钟延迟（~3 至 ~ 40个时钟周期），这取决于缓存的类型。现如今，性能的一方面考量就是如何更高效的将数据放到处理器中。编写需要改变状态的多线程应用程序时需要考虑缓存系统的机制。

![](https://mmbiz.qpic.cn/mmbiz_png/XsgEbl9Edmlazp0d752thScev3HvoLm2MkzuvYLia2C8VyzYEQUTPRfETLwl7v1553u9VZWpwV4yC8LnDcaw1CQ/0?wx_fmt=png)

数据在主存储和处理器之前的传递是通过Cache Line进行的，Cache Line是一块64字节的内存块，用来在主内存和缓存系统之间交换数据。每一个Core都有它需要的Cache Line的拷贝，这意味着硬件使用的值语义(**Value semantics**，区别于指针)。这也是为什么在多线程编程中改变内存可能会带来性能梦魇。

> “**Value semantics** keep values on the stack, which reduces pressure on the Garbage Collector (GC). However, value semantics require various copies of any given value to be stored, tracked and maintained. **Pointer semantics** place values on the heap, which can put pressure on the GC. However, pointer semantics are efficient because only one value needs to be stored, tracked and maintained.” - Bill Kennedy

当并行运行的多个线程访问同一个数据或者相邻内存的数据时将会在相同的Cache Line上访问数据。所以运行在任何Core上的线程都必须拥有一份Cache Line的拷贝。

![](https://mmbiz.qpic.cn/mmbiz_png/XsgEbl9Edmlazp0d752thScev3HvoLm2CiaP9dJJaWxUcBnKkeEZQTiad5ZQ7AHiae1x9V8ibickz4iaXia1iceWRrQ2lA/0?wx_fmt=png)

如果其中一个线程所在的Core对它上面Cache Line的拷贝数据做一个变更，那么所有拥有该Cache Line的拷贝都会被标记为“脏”。当某个线程对被标记为“脏”的Cache Line进行读或者写时，这时候需要有一个访问主内存的步骤（~100 至 ~300个时钟周期）来更新所有的Cache Line。

也许这个事情在有2个Core的处理器上看起来问题不大，但是当有32个线程并行运行在32个Core上并且访问或者改变相同的Cache Line的时候呢？在有2个处理器并且每个处理器都有16个Core的情况下又会是怎样的呢？这将会更加的糟糕，因为处理器-处理器之间的通信也会带来延迟。应用程序性能可能会变得非常糟糕，而且很可能你并不明白为何会这样子。

这个问题被称为**缓存一致性问题**（cache-coherency problem ）并且可能会导致**false sharing**的问题。当你在写可能会改变共同状态的多线程程序的时候，缓存系统也是需要考虑的。

### 调度决策方案
假设让你基于上面的信息写一个操作系统调度器，考虑下面这种工作场景，记住，这种场景只是调度器面对的诸多有趣场景中的一种。

你的应用程序启动，创建主线程，当线程开始执行其指令时，由于需要数据，该线程开始访问Cache Line。因为要进行某些并发处理，线程现在决定创建一个新线程。下面是问题：

当这个新线程被创建并就绪后，调度器是否应该：

1. 将主线程从Core1上切出？这么做可能会增加性能，因为这个新线程可能需要的是同样的数据，而这个数据已经被缓存过。但是主线程没有获得完整的时间片。
2. 这个新线程是否需要等待主线程完成它的工作直到Core1可用？这么做的话线程并不会立即启动，但是一旦它启动，也不会花费数据获取时间。
3. 线程是否应该等待下一个可用的Core？这意味着cache line将被刷新，获取以及拷贝，这都会导致延迟。然而这样做线程可以启动的更快，并且主线程也可以有完整的时间片。

是不是有点意思？在做调度决策时有很多有趣的问题需要调度器考虑。
### 总结
这部分内容主要告诉你在写多线程应用程序时关于线程以及操作系统需要需要考虑那些东西。这些也是Go调度器考虑的内容。在下一部分，我们将讲述Go调度程序的原理以及它是如何和这里的信息关联上的。最后你将会通过运行几个例子更直观的理解这些原理。

